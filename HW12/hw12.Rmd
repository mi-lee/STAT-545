---
title: "HW 12 - Data scraping"
author: "Michelle Lee"
date: "December 8, 2014"
output:
  html_document:
    keep_md: yes
    toc: yes
---

After exploring all the different packages available for data scraping, I decided I wanted to learn how to start from scratch. I picked a simple website, [CareerBuilder](http://www.careerbuilder.com/?sc_cmp2=js_home_cblogo) with a query. For this example, the [query was "data r" jobs](http://www.careerbuilder.com/jobseeker/jobs/jobresults.aspx?qb=1&SB%3Asbkw=r+data&SB%3As_freeloc=&SB%3Asbfr=30&sbsbmt=Find+Jobs&IPath=ILKV&excrit=st%3DA%3Buse%3DALL%3BrawWords%3Dr%3BCID%3DUS%3BSID%3D%3F%3BTID%3D0%3BLOCCID%3DUS%3BENR%3DNO%3BDTP%3DDRNS%3BYDI%3DYES%3BIND%3DALL%3BPDQ%3DAll%3BPDQ%3DAll%3BPAYL%3D0%3BPAYH%3DGT120%3BPOY%3DNO%3BETD%3DALL%3BRE%3DALL%3BMGT%3DDC%3BSUP%3DDC%3BFRE%3D30%3BCHL%3DAL%3BQS%3DSID_UNKNOWN%3BSS%3DNO%3BTITL%3D0%3BOB%3D-relv%3BVT%3DTITLE%3BJQT%3DRAD%3BJDV%3DFalse%3BSITEENT%3DUSJOB%3BMaxLowExp%3D-1%3BRecsPerPage%3D25&cid=US&findjob=sb).

If you want to try it yourself, please click on "Job Titles Only" - I haven't yet figured out how to manage the rest. 

I first loaded the libraries:

```{r}
library(rvest)
library(httr)
```

I obtained the url (remember to click the "Title only" option!), using `httr` and `rvest`:

```{r}
html <- html("http://www.careerbuilder.com/jobseeker/jobs/jobresults.aspx?qb=1&SB%3Asbkw=r+data&SB%3As_freeloc=&SB%3Asbfr=30&sbsbmt=Find+Jobs&IPath=ILKV&excrit=st%3DA%3Buse%3DALL%3BrawWords%3Dr%3BCID%3DUS%3BSID%3D%3F%3BTID%3D0%3BLOCCID%3DUS%3BENR%3DNO%3BDTP%3DDRNS%3BYDI%3DYES%3BIND%3DALL%3BPDQ%3DAll%3BPDQ%3DAll%3BPAYL%3D0%3BPAYH%3DGT120%3BPOY%3DNO%3BETD%3DALL%3BRE%3DALL%3BMGT%3DDC%3BSUP%3DDC%3BFRE%3D30%3BCHL%3DAL%3BQS%3DSID_UNKNOWN%3BSS%3DNO%3BTITL%3D0%3BOB%3D-relv%3BVT%3DTITLE%3BJQT%3DRAD%3BJDV%3DFalse%3BSITEENT%3DUSJOB%3BMaxLowExp%3D-1%3BRecsPerPage%3D25&cid=US&findjob=sb")
```

... and then made a function to organize the data:

```{r}
getJobs <- function(url) {
	
	# Clean the title column of job titles
	cleanTitle <- function(html, node) {
		# scrape the data
		text <- html_nodes(html, node)
		
		# clean the data using regex
		text <- gsub("\\n|\\r|\\t|View similar jobs|  | - |", "", html_text(text))
		
		# organize the data into a matrix
		matrix(unlist(strsplit(as.character(text), "    ")))[-1,1]
		}
	title<- cleanTitle(html, ".jl_col2")
	
	# Clean the company column of company names
	cleanComp <- function(html, node) {
		# scrape the data
		text <- html_nodes(html, node)
		
		# clean the data using regex
		text <- gsub("\\n|\\r|\\t|  |", "", html_text(text))
		
		# organize the data into a matrix
		matrix(unlist(strsplit(as.character(text), "$$$")))[-1,1]
		}
	company <- cleanComp(html, ".jl_col3")
	
	# Clean the location column of company names
	cleanLoc <- function(html, node) {
		# scrape the data
		text <- html_nodes(html, node)
		
		# clean the data using regex
		text <- gsub("\\n|\\r|\\t|  |+1 more|Relocate to |+|,", "", html_text(text))
		
		# organize the data into a matrix
		text <- matrix(unlist(strsplit(as.character(text), "$$$")))[-1,1]
		
		# split the column into two: state and city
		text<- as.data.frame(matrix(unlist(strsplit(as.character(text), " - ")), ncol=2, byrow=T))
		}
	loc <- cleanLoc(html, ".jl_col4");loc
	
	# Add "NA" if there is an empty space instead
	cbind.fill <- function(...){
		nm <- list(...) 
		nm <- lapply(nm, as.matrix)
		n <- max(sapply(nm, nrow)) 
		do.call(cbind, lapply(nm, function (x) 
			rbind(x, matrix(, n-nrow(x), ncol(x))))) 
		}
	
	# return the dataset
	data <- as.data.frame(cbind.fill(title, company, loc))
	colnames(data) <- c("title", "company", "state", "city")
	return(data)
	}
```

To try it out:

```{r}
knitr::kable(getJobs(url))
```

To explore the data a bit:

```{r}
x<- getJobs(url)
plot(sort(x$state), main="Histogram of jobs by state")
```


## Reflections

* This assignment took me a very long time, for such little material produced :( I experimented with `httr` and `rvest` a lot, which took a lot of time.

* I had a *lot* of issues when trying to make this, especially on regex, and it's nowhere perfect. One thing that I am still trying to figure out: regex to get rid of the plus sign, '+'. `gsub("\+", "", text)` didn't work, and I tried a number of variations on it, e.g. `\\+`, `\\b[+]`, and so on... 

* The libraries like `rplos` are very convenient in extracting data, and when I have some time, I will be looking at the functions to see how they managed to extract the data so neatly. 

Thanks for reading/marking my assignment! Hope you have a merry Christmas (in 3 weeks)!

